# Speech SDK Learning Module

In this tutorial you will create a [Unity](https://unity3d.com/) application that explores the Azure Cognitive Services Speech SDK.  When finished you will be able to use your computer's microphone to transcribe speech to text in real time, translate your speech into multiple languages, and even take advantage of Speech SDK’s Intent feature that provides for more flexible, AI-driven uses. If you are not familiar with Unity, it is recommended to study the [Unity User Manual](https://docs.unity3d.com/Manual/UnityManual.html) before starting your application development.

Objectives:

- Learn how to _____________________________________________

- Learn how to _________________________________________________

  

## Instructions

### Getting Started

1. Start Unity and create a new project. Enter the project name “Speech SDK Learning Module.” Choose a location for where to save your project.

![Module2Chapter3step1im](C:images/module4Chapter1Step1im.PNG)

2. 

   

   ![Module2Chapter3step2im](C:/Users/jerem/OneDrive/Documents/GitHub/mixed-reality/mixed-reality-docs/images/Module2chapter3step2im.png)

   3. Adjust the scale and the positioning of the text so that it matches with the instructions in your scene. Also, ensure the alignment for all of the text is centered. Then delete the sample text from the text editor. Use the image below to help. 

![Module2Chapter3step3im](C:/Users/jerem/OneDrive/Documents/GitHub/mixed-reality/mixed-reality-docs/images/Module2chapter3step3im.png)

4. Change the name of the textmeshpro object to "feedbackPanel."

   ![Module2Chapter3step4im](C:/Users/jerem/OneDrive/Documents/GitHub/mixed-reality/mixed-reality-docs/images/Module2chapter3step4im.PNG)

5. In the project panel, select "assets" and right click, then select "show in explorer."

![Module2Chapter3step4im](C:/Users/jerem/OneDrive/Documents/GitHub/mixed-reality/mixed-reality-docs/images/Module2chapter3step5im.png)

Now, click [here](https://onedrive.live.com/?authkey=%21ABXEC8PvyQu8Qd8&id=5B7335C4342BCB0E%21395636&cid=5B7335C4342BCB0E) to download the files needed in the next few steps.

6. Once explorer opens, select the assets folder, then the "ASAModulesAssets" folder, and copy the anchor feedback script and the anchor module script files into the folder. 

![Module2Chapter3step5im](C:/Users/jerem/OneDrive/Documents/GitHub/mixed-reality/mixed-reality-docs/images/Module2chapter3step6im.png)

> note: if you get a pop-up asking you if you would like to overwrite the old or keep the old make sure you select overwrite.

7. Now return to the Assets folder. Then, go into the "AzureSpatialAnchorsPlugin" folder, then the examples folder, and finally the scripts folder, and copy the Azure Spatial Anchors demo wrapper into that folder. 

![Module2Chapter3step8im](C:/Users/jerem/OneDrive/Documents/GitHub/mixed-reality/mixed-reality-docs/images/Module2chapter3step7im.png)

8. Now that the files are uploaded, ensure that the "feedbackpanel" text is selected, in the ASA_feedback hierarchy and click "add component" and add the anchor feedback script by searching for it and selecting it once it appears. 

   ** needs one more screenshot showing which text file is selected in hierarchy.**

![Module2Chapter3step8im](C:/Users/jerem/OneDrive/Documents/GitHub/mixed-reality/mixed-reality-docs/images/Module2chapter3step8im.png)

9. Drag the "feedbackPanel" text object from the ASA_Feedback hierarchy into the empty slot beneath the script as seen in the picture below. 

   #### ![Module2Chapter3step9im](C:/Users/jerem/OneDrive/Documents/GitHub/mixed-reality/mixed-reality-docs/images/Module2chapter3step9im.png)

   TODO: let me know, if I need to get the project file and update "TexMeshPro" name "feedbackpanel" instead of the above screenshot.

## Congratulations

[Next Lesson: ASA Lesson 4](mrlearning-base-ch4.md)

